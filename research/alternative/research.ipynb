{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.ml.corpus import CorpusReader\n",
    "import re\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CorpusReader(Loc.corpus_path/'lenta.base.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = reader.get_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = frames.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195000</th>\n",
       "      <td>195000</td>\n",
       "      <td>195000</td>\n",
       "      <td>0</td>\n",
       "      <td>195000</td>\n",
       "      <td>1</td>\n",
       "      <td>Организатор</td>\n",
       "      <td>ru</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195001</th>\n",
       "      <td>195001</td>\n",
       "      <td>195000</td>\n",
       "      <td>1</td>\n",
       "      <td>195000</td>\n",
       "      <td>1</td>\n",
       "      <td>экстремального</td>\n",
       "      <td>ru</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195002</th>\n",
       "      <td>195002</td>\n",
       "      <td>195000</td>\n",
       "      <td>2</td>\n",
       "      <td>195000</td>\n",
       "      <td>1</td>\n",
       "      <td>аттракциона</td>\n",
       "      <td>ru</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195003</th>\n",
       "      <td>195003</td>\n",
       "      <td>195000</td>\n",
       "      <td>3</td>\n",
       "      <td>195000</td>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195004</th>\n",
       "      <td>195004</td>\n",
       "      <td>195000</td>\n",
       "      <td>4</td>\n",
       "      <td>195000</td>\n",
       "      <td>0</td>\n",
       "      <td>Карачаево-Черкесии</td>\n",
       "      <td>ru</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_id  sentence_id  word_index  paragraph_id  word_tail  \\\n",
       "195000   195000       195000           0        195000          1   \n",
       "195001   195001       195000           1        195000          1   \n",
       "195002   195002       195000           2        195000          1   \n",
       "195003   195003       195000           3        195000          1   \n",
       "195004   195004       195000           4        195000          0   \n",
       "\n",
       "                      word word_type  word_length  original_word_id  \\\n",
       "195000         Организатор        ru           11                 0   \n",
       "195001      экстремального        ru           14                 1   \n",
       "195002         аттракциона        ru           11                 2   \n",
       "195003                   в        ru            1                 3   \n",
       "195004  Карачаево-Черкесии        ru           18                 4   \n",
       "\n",
       "        original_sentence_id  original_paragraph_id  updated  \\\n",
       "195000                     0                      0    False   \n",
       "195001                     0                      0    False   \n",
       "195002                     0                      0    False   \n",
       "195003                     0                      0    False   \n",
       "195004                     0                      0    False   \n",
       "\n",
       "                                     file_id       corpus_id  \n",
       "195000  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip  \n",
       "195001  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip  \n",
       "195002  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip  \n",
       "195003  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip  \n",
       "195004  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтобы что бы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chto_by(df):\n",
    "    what = df[df['word'] == 'что']\n",
    "    what_next = what[['sentence_id', 'word_index']].copy()\n",
    "    what_next['word_index'] += 1\n",
    "    what_neighbour = df.merge(what_next, on=['sentence_id', 'word_index'], how='inner')\n",
    "    \n",
    "    by = what_neighbour[what_neighbour['word'] == 'бы']\n",
    "    \n",
    "    return pd.concat([what.merge(by['word_id'] - 1, on=['word_id'], how='inner'), by]).sort_values(['word_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241295</td>\n",
       "      <td>197321</td>\n",
       "      <td>22</td>\n",
       "      <td>195180</td>\n",
       "      <td>1</td>\n",
       "      <td>что</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "      <td>46295</td>\n",
       "      <td>2321</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>241296</td>\n",
       "      <td>197321</td>\n",
       "      <td>23</td>\n",
       "      <td>195180</td>\n",
       "      <td>1</td>\n",
       "      <td>бы</td>\n",
       "      <td>ru</td>\n",
       "      <td>2</td>\n",
       "      <td>46296</td>\n",
       "      <td>2321</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_id  sentence_id  word_index  paragraph_id  word_tail word word_type  \\\n",
       "0     241295       197321          22        195180          1  что        ru   \n",
       "438   241296       197321          23        195180          1   бы        ru   \n",
       "\n",
       "     word_length  original_word_id  original_sentence_id  \\\n",
       "0              3             46295                  2321   \n",
       "438            2             46296                  2321   \n",
       "\n",
       "     original_paragraph_id  updated                               file_id  \\\n",
       "0                      180    False  092b10a4-1328-4cd6-bae6-0367fd502a19   \n",
       "438                    180    False  092b10a4-1328-4cd6-bae6-0367fd502a19   \n",
       "\n",
       "          corpus_id original_corpus_id  is_target  \n",
       "0    lenta.base.zip     lenta.base.zip       True  \n",
       "438  lenta.base.zip     lenta.base.zip      False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chto_by = get_chto_by(df)\n",
    "chto_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(df):\n",
    "    targets = df.set_index('word_id').word.str.lower() == 'чтобы'\n",
    "\n",
    "    chto = df[df['word'] == 'что']\n",
    "    chto_next = chto['word_id'] + 1\n",
    "    chto_neighbour = df.merge(chto_next, how='inner')\n",
    "    by = chto_neighbour[chto_neighbour['word'] == 'бы']\n",
    "\n",
    "    targets[by['word_id'] - 1] = True\n",
    "\n",
    "    return targets.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative sample building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.copy()\n",
    "chtoby = result['word'] == 'чтобы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14)\n"
     ]
    }
   ],
   "source": [
    "# transforming 'что' + 'бы' to 'чтобы'\n",
    "chto = result[result['word'] == 'что']\n",
    "chto_next = chto[['sentence_id', 'word_index']].copy()\n",
    "chto_next['word_index'] += 1\n",
    "chto_neighbor = result.merge(chto_next, on=['sentence_id', 'word_index'], how='inner')\n",
    "by = chto_neighbor[chto_neighbor['word'] == 'бы']\n",
    "\n",
    "print(by.shape)\n",
    "\n",
    "if by.shape[0] != 0:\n",
    "    chto_with_pair_loc = by['word_id']\n",
    "    result.loc[chto_with_pair_loc - 1, 'word'] = 'чтобы'\n",
    "    result.loc[chto_with_pair_loc - 1, 'word_length'] += 3\n",
    "\n",
    "    result = result.drop(chto_with_pair_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.common.separator import Separator\n",
    "# transforming 'чтобы' to 'что' + 'бы'\n",
    "result.loc[chtoby, 'word'] = 'что бы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Separator.separate_string(Separator.Viewer().to_text(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tg.grammar_ru.ml.tasks.train_index_builder.index_builders import ChtobyIndexBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tg.grammar_ru.ml.tasks.train_index_builder import index_builders\n",
    "\n",
    "ChtobyIndexBuilder = importlib.reload(index_builders).ChtobyIndexBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = ChtobyIndexBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = builder.build_train_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive, negative = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>reference_sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197286</th>\n",
       "      <td>197286</td>\n",
       "      <td>195112</td>\n",
       "      <td>0</td>\n",
       "      <td>195007</td>\n",
       "      <td>1</td>\n",
       "      <td>Я</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>2286</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197287</th>\n",
       "      <td>197287</td>\n",
       "      <td>195112</td>\n",
       "      <td>1</td>\n",
       "      <td>195007</td>\n",
       "      <td>1</td>\n",
       "      <td>чувствую</td>\n",
       "      <td>ru</td>\n",
       "      <td>8</td>\n",
       "      <td>2287</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197288</th>\n",
       "      <td>197288</td>\n",
       "      <td>195112</td>\n",
       "      <td>2</td>\n",
       "      <td>195007</td>\n",
       "      <td>1</td>\n",
       "      <td>себя</td>\n",
       "      <td>ru</td>\n",
       "      <td>4</td>\n",
       "      <td>2288</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197289</th>\n",
       "      <td>197289</td>\n",
       "      <td>195112</td>\n",
       "      <td>3</td>\n",
       "      <td>195007</td>\n",
       "      <td>0</td>\n",
       "      <td>так</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "      <td>2289</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197290</th>\n",
       "      <td>197290</td>\n",
       "      <td>195112</td>\n",
       "      <td>4</td>\n",
       "      <td>195007</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "      <td>2290</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428867</th>\n",
       "      <td>428867</td>\n",
       "      <td>206927</td>\n",
       "      <td>22</td>\n",
       "      <td>195926</td>\n",
       "      <td>1</td>\n",
       "      <td>и</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>233867</td>\n",
       "      <td>11927</td>\n",
       "      <td>926</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428868</th>\n",
       "      <td>428868</td>\n",
       "      <td>206927</td>\n",
       "      <td>23</td>\n",
       "      <td>195926</td>\n",
       "      <td>1</td>\n",
       "      <td>исключить</td>\n",
       "      <td>ru</td>\n",
       "      <td>9</td>\n",
       "      <td>233868</td>\n",
       "      <td>11927</td>\n",
       "      <td>926</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428869</th>\n",
       "      <td>428869</td>\n",
       "      <td>206927</td>\n",
       "      <td>24</td>\n",
       "      <td>195926</td>\n",
       "      <td>1</td>\n",
       "      <td>возможность</td>\n",
       "      <td>ru</td>\n",
       "      <td>11</td>\n",
       "      <td>233869</td>\n",
       "      <td>11927</td>\n",
       "      <td>926</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428870</th>\n",
       "      <td>428870</td>\n",
       "      <td>206927</td>\n",
       "      <td>25</td>\n",
       "      <td>195926</td>\n",
       "      <td>0</td>\n",
       "      <td>провокации</td>\n",
       "      <td>ru</td>\n",
       "      <td>10</td>\n",
       "      <td>233870</td>\n",
       "      <td>11927</td>\n",
       "      <td>926</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428871</th>\n",
       "      <td>428871</td>\n",
       "      <td>206927</td>\n",
       "      <td>26</td>\n",
       "      <td>195926</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "      <td>233871</td>\n",
       "      <td>11927</td>\n",
       "      <td>926</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4131 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_id  sentence_id  word_index  paragraph_id  word_tail  \\\n",
       "197286   197286       195112           0        195007          1   \n",
       "197287   197287       195112           1        195007          1   \n",
       "197288   197288       195112           2        195007          1   \n",
       "197289   197289       195112           3        195007          0   \n",
       "197290   197290       195112           4        195007          1   \n",
       "...         ...          ...         ...           ...        ...   \n",
       "428867   428867       206927          22        195926          1   \n",
       "428868   428868       206927          23        195926          1   \n",
       "428869   428869       206927          24        195926          1   \n",
       "428870   428870       206927          25        195926          0   \n",
       "428871   428871       206927          26        195926          1   \n",
       "\n",
       "               word word_type  word_length  original_word_id  \\\n",
       "197286            Я        ru            1              2286   \n",
       "197287     чувствую        ru            8              2287   \n",
       "197288         себя        ru            4              2288   \n",
       "197289          так        ru            3              2289   \n",
       "197290            ,     punct            1              2290   \n",
       "...             ...       ...          ...               ...   \n",
       "428867            и        ru            1            233867   \n",
       "428868    исключить        ru            9            233868   \n",
       "428869  возможность        ru           11            233869   \n",
       "428870   провокации        ru           10            233870   \n",
       "428871            .     punct            1            233871   \n",
       "\n",
       "        original_sentence_id  original_paragraph_id  updated  \\\n",
       "197286                   112                      7    False   \n",
       "197287                   112                      7    False   \n",
       "197288                   112                      7    False   \n",
       "197289                   112                      7    False   \n",
       "197290                   112                      7    False   \n",
       "...                      ...                    ...      ...   \n",
       "428867                 11927                    926    False   \n",
       "428868                 11927                    926    False   \n",
       "428869                 11927                    926    False   \n",
       "428870                 11927                    926    False   \n",
       "428871                 11927                    926    False   \n",
       "\n",
       "                                     file_id       corpus_id  \\\n",
       "197286  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "197287  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "197288  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "197289  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "197290  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "...                                      ...             ...   \n",
       "428867  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "428868  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "428869  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "428870  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "428871  092b10a4-1328-4cd6-bae6-0367fd502a19  lenta.base.zip   \n",
       "\n",
       "       original_corpus_id  is_target  label  reference_sentence_id  \n",
       "197286     lenta.base.zip      False      0                      0  \n",
       "197287     lenta.base.zip      False      0                      0  \n",
       "197288     lenta.base.zip      False      0                      0  \n",
       "197289     lenta.base.zip      False      0                      0  \n",
       "197290     lenta.base.zip      False      0                      0  \n",
       "...                   ...        ...    ...                    ...  \n",
       "428867     lenta.base.zip      False      0                    158  \n",
       "428868     lenta.base.zip      False      0                    158  \n",
       "428869     lenta.base.zip      False      0                    158  \n",
       "428870     lenta.base.zip      False      0                    158  \n",
       "428871     lenta.base.zip      False      0                    158  \n",
       "\n",
       "[4131 rows x 18 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = builder._build_negative_from_positive(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>reference_sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241295</th>\n",
       "      <td>241295</td>\n",
       "      <td>197321</td>\n",
       "      <td>22</td>\n",
       "      <td>195180</td>\n",
       "      <td>1</td>\n",
       "      <td>чтобы</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>46295</td>\n",
       "      <td>2321</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_id  sentence_id  word_index  paragraph_id  word_tail   word  \\\n",
       "241295   241295       197321          22        195180          1  чтобы   \n",
       "\n",
       "       word_type  word_length  original_word_id  original_sentence_id  \\\n",
       "241295        ru            6             46295                  2321   \n",
       "\n",
       "        original_paragraph_id  updated                               file_id  \\\n",
       "241295                    180    False  092b10a4-1328-4cd6-bae6-0367fd502a19   \n",
       "\n",
       "             corpus_id original_corpus_id  is_target  label  \\\n",
       "241295  lenta.base.zip     lenta.base.zip       True      1   \n",
       "\n",
       "        reference_sentence_id  \n",
       "241295                     27  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[negative['word'] == 'чтобы']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>reference_sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word_id, sentence_id, word_index, paragraph_id, word_tail, word, word_type, word_length, original_word_id, original_sentence_id, original_paragraph_id, updated, file_id, corpus_id, original_corpus_id, is_target, label, reference_sentence_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg[neg['word'] == 'чтобы']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = ChtobyIndexBuilder().build_train_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>reference_sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241295</th>\n",
       "      <td>241295</td>\n",
       "      <td>197321</td>\n",
       "      <td>22</td>\n",
       "      <td>195180</td>\n",
       "      <td>1</td>\n",
       "      <td>чтобы</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>46295</td>\n",
       "      <td>2321</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>092b10a4-1328-4cd6-bae6-0367fd502a19</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_id  sentence_id  word_index  paragraph_id  word_tail   word  \\\n",
       "241295   241295       197321          22        195180          1  чтобы   \n",
       "\n",
       "       word_type  word_length  original_word_id  original_sentence_id  \\\n",
       "241295        ru            6             46295                  2321   \n",
       "\n",
       "        original_paragraph_id  updated                               file_id  \\\n",
       "241295                    180    False  092b10a4-1328-4cd6-bae6-0367fd502a19   \n",
       "\n",
       "             corpus_id original_corpus_id  is_target  label  \\\n",
       "241295  lenta.base.zip     lenta.base.zip       True      1   \n",
       "\n",
       "        reference_sentence_id  \n",
       "241295                     27  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg[neg['word'] == 'чтобы']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tg.grammar_ru.common import Loc\n",
    "from research.common import run_training\n",
    "\n",
    "\n",
    "bundle_name = 'big'\n",
    "bundle_path = Loc.bundles_path/f'chtoby/{bundle_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-23 09:55:20.780737+00:00 INFO: Training starts. Info: {'name': 'TSAG-'}\n",
      "2022-11-23 09:55:20.871025+00:00 INFO: Ensuring/loading bundle. Bundle before:\n",
      "{'slovnet': {'shape': (6747861, 18), 'index_name': 'word_id'}, 'syntax_fixes': {'shape': (6747861, 4), 'index_name': 'word_id'}, 'syntax_stats': {'shape': (6747861, 6), 'index_name': 'word_id'}, 'index': {'shape': (266027, 5), 'index_name': 'sample_id'}, 'syntax_closure': {'shape': (18338761, 4), 'index_name': 'entry_id'}, 'src': {'shape': (6747861, 18), 'index_name': None}, 'pymorphy': {'shape': (6747861, 16), 'index_name': 'word_id'}}\n",
      "2022-11-23 09:55:20.899514+00:00 INFO: Bundle loaded\n",
      "{'slovnet': {'shape': (6747861, 18), 'index_name': 'word_id', 'columns': ['POS', 'Case', 'Degree', 'Gender', 'Number', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'syntax_fixes': {'shape': (6747861, 4), 'index_name': 'word_id', 'columns': ['syntax_parent_id', 'root', 'cycle_status', 'correct_root'], 'index': [0, 1, 2, 3, 4, '...']}, 'syntax_stats': {'shape': (6747861, 6), 'index_name': 'word_id', 'columns': ['children', 'descendants', 'up_depth', 'down_depth', 'sentence_length', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'index': {'shape': (266027, 5), 'index_name': 'sample_id', 'columns': ['word_id', 'sentence_id', 'label', 'reference_sentence_id', 'split'], 'index': [0, 1, 2, 3, 4, '...']}, 'syntax_closure': {'shape': (18338761, 4), 'index_name': 'entry_id', 'columns': ['word_id', 'syntax_parent_id', 'relation', 'distance'], 'index': [0, 1, 2, 3, 4, '...']}, 'src': {'shape': (6747861, 18), 'index_name': None, 'columns': ['word_id', 'sentence_id', 'word_index', 'paragraph_id', 'word_tail', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'pymorphy': {'shape': (6747861, 16), 'index_name': 'word_id', 'columns': ['normal_form', 'alternatives', 'score', 'delta_score', 'POS', '...'], 'index': [0, 1, 2, 3, 4, '...']}}\n",
      "2022-11-23 09:55:20.901990+00:00 INFO: Index frame is set to index, shape is (266027, 5)\n",
      "2022-11-23 09:55:20.904081+00:00 INFO: Running late initizalization\n",
      "2022-11-23 09:55:20.906313+00:00 INFO: No basis tasks are available\n",
      "2022-11-23 09:55:20.907286+00:00 INFO: Preprocessing bundle\n",
      "2022-11-23 09:55:20.909098+00:00 INFO: Creating extractors\n",
      "2022-11-23 09:55:20.920588+00:00 INFO: Extractors: plain_context, label\n",
      "2022-11-23 09:55:20.925100+00:00 INFO: Setting batcher\n",
      "2022-11-23 09:55:20.930899+00:00 INFO: Preprocessing bundle by batcher\n",
      "2022-11-23 09:55:21.040724+00:00 INFO: Splits: train 186218, test 79809, display 79808\n",
      "2022-11-23 09:55:21.041587+00:00 INFO: New training. Instantiating the system\n",
      "2022-11-23 09:55:21.067178+00:00 INFO: Fitting the transformers\n",
      "2022-11-23 09:55:21.275822+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-11-23 09:55:26.697265+00:00 INFO: Success\n",
      "2022-11-23 09:55:26.698603+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-11-23 09:55:30.442815+00:00 INFO: Success\n",
      "2022-11-23 09:55:30.443627+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-11-23 09:55:31.899078+00:00 INFO: Success\n",
      "2022-11-23 09:55:31.899953+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-11-23 09:55:33.448397+00:00 INFO: Success\n",
      "2022-11-23 09:55:33.449453+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-11-23 09:55:34.919794+00:00 INFO: Success\n",
      "2022-11-23 09:55:59.484519+00:00 INFO: Instantiating model\n",
      "2022-11-23 09:55:59.843468+00:00 INFO: Initialization completed\n",
      "2022-11-23 09:55:59.857035+00:00 INFO: Epoch 0 of 50\n",
      "2022-11-23 09:56:09.117988+00:00 INFO: Training: 0/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:56:09.410591+00:00 INFO: Training: 0/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:56:09.651737+00:00 INFO: Training: 0/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:56:09.889184+00:00 INFO: Training: 0/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:56:19.460419+00:00 INFO: Training: 1/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:56:19.699955+00:00 INFO: Training: 1/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:56:19.944801+00:00 INFO: Training: 1/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:56:20.185987+00:00 INFO: Training: 1/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:56:30.119443+00:00 INFO: Training: 2/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:56:30.364598+00:00 INFO: Training: 2/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:56:30.608010+00:00 INFO: Training: 2/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:56:30.853416+00:00 INFO: Training: 2/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:56:40.502426+00:00 INFO: Training: 3/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:56:40.737648+00:00 INFO: Training: 3/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:56:40.971040+00:00 INFO: Training: 3/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:56:41.200842+00:00 INFO: Training: 3/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:56:51.247884+00:00 INFO: Training: 4/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:56:51.505451+00:00 INFO: Training: 4/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:56:51.732341+00:00 INFO: Training: 4/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:56:51.977746+00:00 INFO: Training: 4/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:57:01.790618+00:00 INFO: Training: 5/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:57:02.041465+00:00 INFO: Training: 5/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:57:02.283878+00:00 INFO: Training: 5/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:57:02.527520+00:00 INFO: Training: 5/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:57:12.438610+00:00 INFO: Training: 6/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:57:12.687539+00:00 INFO: Training: 6/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:57:12.928539+00:00 INFO: Training: 6/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:57:13.166909+00:00 INFO: Training: 6/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:57:22.876480+00:00 INFO: Training: 7/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:57:23.116247+00:00 INFO: Training: 7/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:57:23.350208+00:00 INFO: Training: 7/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:57:23.586291+00:00 INFO: Training: 7/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:57:33.375097+00:00 INFO: Training: 8/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:57:33.621446+00:00 INFO: Training: 8/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:57:33.853544+00:00 INFO: Training: 8/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:57:34.086677+00:00 INFO: Training: 8/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:57:43.469460+00:00 INFO: Training: 9/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 09:57:43.702883+00:00 INFO: Training: 9/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 09:57:43.951950+00:00 INFO: Training: 9/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 09:57:44.187223+00:00 INFO: Training: 9/38 batch, 3/4 mini-epoch\n",
      "2022-11-23 09:57:53.952025+00:00 INFO: Interrupted because of the training_batch_limit\n",
      "2022-11-23 09:57:53.958562+00:00 INFO: test: 0/16\n",
      "2022-11-23 09:58:03.628186+00:00 INFO: test: 1/16\n",
      "2022-11-23 09:58:13.136699+00:00 INFO: test: 2/16\n",
      "2022-11-23 09:58:22.214612+00:00 INFO: test: 3/16\n",
      "2022-11-23 09:58:31.335103+00:00 INFO: test: 4/16\n",
      "2022-11-23 09:58:41.119226+00:00 INFO: test: 5/16\n",
      "2022-11-23 09:58:51.905963+00:00 INFO: test: 6/16\n",
      "2022-11-23 09:59:02.457167+00:00 INFO: test: 7/16\n",
      "2022-11-23 09:59:13.324191+00:00 INFO: test: 8/16\n",
      "2022-11-23 09:59:24.236609+00:00 INFO: test: 9/16\n",
      "2022-11-23 09:59:35.645661+00:00 INFO: display: 0/16\n",
      "2022-11-23 09:59:44.583445+00:00 INFO: display: 1/16\n",
      "2022-11-23 09:59:53.683109+00:00 INFO: display: 2/16\n",
      "2022-11-23 10:00:03.056721+00:00 INFO: display: 3/16\n",
      "2022-11-23 10:00:12.048340+00:00 INFO: display: 4/16\n",
      "2022-11-23 10:00:21.168084+00:00 INFO: display: 5/16\n",
      "2022-11-23 10:00:31.047930+00:00 INFO: display: 6/16\n",
      "2022-11-23 10:00:40.400513+00:00 INFO: display: 7/16\n",
      "2022-11-23 10:00:49.854600+00:00 INFO: display: 8/16\n",
      "2022-11-23 10:00:59.154124+00:00 INFO: display: 9/16\n",
      "2022-11-23 10:01:08.492024+00:00 INFO: ###roc_auc_score_test:0.9979731107165786\n",
      "2022-11-23 10:01:08.492742+00:00 INFO: ###roc_auc_score_display:0.9978710119454978\n",
      "2022-11-23 10:01:08.493187+00:00 INFO: ###loss:0.04522999360738322\n",
      "2022-11-23 10:01:08.493658+00:00 INFO: ###iteration:0\n",
      "2022-11-23 10:01:08.494200+00:00 INFO: Epoch 1 of 50\n",
      "2022-11-23 10:01:18.299927+00:00 INFO: Training: 0/38 batch, 0/4 mini-epoch\n",
      "2022-11-23 10:01:18.624771+00:00 INFO: Training: 0/38 batch, 1/4 mini-epoch\n",
      "2022-11-23 10:01:18.963692+00:00 INFO: Training: 0/38 batch, 2/4 mini-epoch\n",
      "2022-11-23 10:01:19.228244+00:00 INFO: Training: 0/38 batch, 3/4 mini-epoch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/alabai/studies/grammar_ru/grammar_ru/research/alternative/n_nn/research.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alabai/studies/grammar_ru/grammar_ru/research/alternative/n_nn/research.ipynb#ch0000087?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m run_training\u001b[39m.\u001b[39;49mrun_local(bundle_path)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/research/common/run_training.py:70\u001b[0m, in \u001b[0;36mrun_local\u001b[0;34m(bundle_path)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/research/common/run_training.py?line=66'>67</a>\u001b[0m task\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mevaluation_batch_limit \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/research/common/run_training.py?line=67'>68</a>\u001b[0m bundle \u001b[39m=\u001b[39m bt\u001b[39m.\u001b[39mDataBundle\u001b[39m.\u001b[39mload(bundle_path)\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/research/common/run_training.py?line=69'>70</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (task, task\u001b[39m.\u001b[39;49mrun(bundle))\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/training_core/arch.py:78\u001b[0m, in \u001b[0;36mAbstractTrainingTask.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/training_core/arch.py?line=75'>76</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, data: Any):\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/training_core/arch.py?line=76'>77</a>\u001b[0m     env \u001b[39m=\u001b[39m InMemoryTrainingEnvironment()\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/training_core/arch.py?line=77'>78</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_with_environment(data, env)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/training_core/arch.py?line=78'>79</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m env\u001b[39m.\u001b[39mresult\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py:366\u001b[0m, in \u001b[0;36mBatchedTrainingTask.run_with_environment\u001b[0;34m(self, _bundle, env)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=363'>364</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_simple_epoch(temp_data)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=364'>365</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=365'>366</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch_with_minibatches(temp_data)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=366'>367</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mdelay_after_iteration_in_seconds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=367'>368</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mdelay_after_iteration_in_seconds)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py:331\u001b[0m, in \u001b[0;36mBatchedTrainingTask._train_epoch_with_minibatches\u001b[0;34m(self, temp_data)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=328'>329</a>\u001b[0m \u001b[39mif\u001b[39;00m terminate:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=329'>330</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=330'>331</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatcher\u001b[39m.\u001b[39;49mget_batch(temp_data\u001b[39m.\u001b[39;49mtrain_bundle, i)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=331'>332</a>\u001b[0m temp_data\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m batch\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/training_task.py?line=332'>333</a>\u001b[0m mini_epochs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mmini_epoch_count \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py:69\u001b[0m, in \u001b[0;36mBatcher.get_batch\u001b[0;34m(self, db, batch_index, force_default_strategy)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=59'>60</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=60'>61</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=61'>62</a>\u001b[0m \u001b[39m    db:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=65'>66</a>\u001b[0m \u001b[39mReturns: a dictionary with batch component, one per key of ``self.transformers``\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=66'>67</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=67'>68</a>\u001b[0m index_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batch_index(db, batch_index, force_default_strategy)\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=68'>69</a>\u001b[0m batch \u001b[39m=\u001b[39m Extractor\u001b[39m.\u001b[39;49mmake_extraction(db\u001b[39m.\u001b[39;49mchange_index(index_df), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextractors)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/batcher.py?line=69'>70</a>\u001b[0m \u001b[39mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py:49\u001b[0m, in \u001b[0;36mExtractor.make_extraction\u001b[0;34m(ibundle, extractors)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m extractor \u001b[39min\u001b[39;00m extractors:\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=47'>48</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=48'>49</a>\u001b[0m         rs \u001b[39m=\u001b[39m extractor\u001b[39m.\u001b[39;49mextract(ibundle)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=49'>50</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=50'>51</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError when extracting from extractor `\u001b[39m\u001b[39m{\u001b[39;00mextractor\u001b[39m.\u001b[39mget_name()\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py:126\u001b[0m, in \u001b[0;36mContextExtractor.extract\u001b[0;34m(self, ibundle)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=123'>124</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=124'>125</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_ \u001b[39m=\u001b[39m data\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=125'>126</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_till_finalization(data)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=126'>127</a>\u001b[0m data\u001b[39m.\u001b[39mresult_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer\u001b[39m.\u001b[39mfinalize(ibundle\u001b[39m.\u001b[39mindex_frame, data\u001b[39m.\u001b[39mfeature_dfs, data\u001b[39m.\u001b[39magg_dfs)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=127'>128</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mresult_df\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py:103\u001b[0m, in \u001b[0;36mContextExtractor._extract_till_finalization\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=100'>101</a>\u001b[0m data\u001b[39m.\u001b[39mcontext_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_builder\u001b[39m.\u001b[39mbuild_context(data\u001b[39m.\u001b[39mibundle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_size)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=101'>102</a>\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mcontext_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=102'>103</a>\u001b[0m     ExtractorToAggregator\u001b[39m.\u001b[39;49mapply_several(data\u001b[39m.\u001b[39;49mibundle\u001b[39m.\u001b[39;49mchange_index(data\u001b[39m.\u001b[39;49mcontext_df), data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextractors_and_aggregators)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py:46\u001b[0m, in \u001b[0;36mExtractorToAggregator.apply_several\u001b[0;34m(context_ibundle, data, extractors_and_aggregators)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=42'>43</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_several\u001b[39m(context_ibundle: IndexedDataBundle, data, extractors_and_aggregators: List[\u001b[39m'\u001b[39m\u001b[39mExtractorToAggregator\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=44'>45</a>\u001b[0m     \u001b[39mfor\u001b[39;00m extractor_index, ea \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(extractors_and_aggregators):\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=45'>46</a>\u001b[0m         fdf \u001b[39m=\u001b[39m ea\u001b[39m.\u001b[39;49mextractor\u001b[39m.\u001b[39;49mextract(context_ibundle)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=46'>47</a>\u001b[0m         data\u001b[39m.\u001b[39mfeature_dfs[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m{\u001b[39;00mextractor_index\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fdf\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/context/architecture.py?line=47'>48</a>\u001b[0m         \u001b[39mfor\u001b[39;00m aggregator_index, a \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ea\u001b[39m.\u001b[39maggregators):\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/grammar_ru/ml/components/core_extractor/extractor.py:56\u001b[0m, in \u001b[0;36mCoreExtractor.extract\u001b[0;34m(self, ibundle)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/grammar_ru/ml/components/core_extractor/extractor.py?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract\u001b[39m(\u001b[39mself\u001b[39m, ibundle):\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/grammar_ru/ml/components/core_extractor/extractor.py?line=54'>55</a>\u001b[0m     extractors \u001b[39m=\u001b[39m [c\u001b[39m.\u001b[39mextractor \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextractors\u001b[39m.\u001b[39mvalues() \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m c\u001b[39m.\u001b[39mdisabled]\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/grammar_ru/ml/components/core_extractor/extractor.py?line=55'>56</a>\u001b[0m     df \u001b[39m=\u001b[39m bt\u001b[39m.\u001b[39;49mCombinedExtractor\u001b[39m.\u001b[39;49m_run_extractors(ibundle, extractors)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/grammar_ru/ml/components/core_extractor/extractor.py?line=56'>57</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py:69\u001b[0m, in \u001b[0;36mCombinedExtractor._run_extractors\u001b[0;34m(ibundle, extractors)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=66'>67</a>\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=67'>68</a>\u001b[0m \u001b[39mfor\u001b[39;00m extractor \u001b[39min\u001b[39;00m extractors:\n\u001b[0;32m---> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=68'>69</a>\u001b[0m     frame \u001b[39m=\u001b[39m extractor\u001b[39m.\u001b[39;49mextract(ibundle)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=69'>70</a>\u001b[0m     frame\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [extractor\u001b[39m.\u001b[39mget_name() \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m frame\u001b[39m.\u001b[39mcolumns]\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/extractors.py?line=70'>71</a>\u001b[0m     frames\u001b[39m.\u001b[39mappend(frame)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py:138\u001b[0m, in \u001b[0;36mPlainExtractor.extract\u001b[0;34m(self, ibundle)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract\u001b[39m(\u001b[39mself\u001b[39m, ibundle: IndexedDataBundle) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=137'>138</a>\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_frame(ibundle)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=138'>139</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=139'>140</a>\u001b[0m         frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mtransform(frame)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py:119\u001b[0m, in \u001b[0;36mPlainExtractor._build_frame\u001b[0;34m(self, ibundle)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=115'>116</a>\u001b[0m     how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=117'>118</a>\u001b[0m join_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoins[join_index \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mkeep_columns\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=118'>119</a>\u001b[0m current \u001b[39m=\u001b[39m current\u001b[39m.\u001b[39;49mmerge(frame, left_on\u001b[39m=\u001b[39;49mjoin_columns, right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, how\u001b[39m=\u001b[39;49mhow)\u001b[39m.\u001b[39mdrop(join_columns, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=120'>121</a>\u001b[0m \u001b[39mif\u001b[39;00m current\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m ibundle\u001b[39m.\u001b[39mindex_frame\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/tg/common/ml/batched_training/plain_extractor.py?line=121'>122</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError in extractor \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: when merging with \u001b[39m\u001b[39m{\u001b[39;00mjoin\u001b[39m.\u001b[39mframe\u001b[39m}\u001b[39;00m\u001b[39m, less rows are produced, \u001b[39m\u001b[39m{\u001b[39;00mcurrent\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m instead \u001b[39m\u001b[39m{\u001b[39;00mibundle\u001b[39m.\u001b[39mindex_frame\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m. Are some rows missing?\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py:9351\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9331'>9332</a>\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9332'>9333</a>\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9333'>9334</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9346'>9347</a>\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9347'>9348</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9348'>9349</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[0;32m-> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9350'>9351</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9351'>9352</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9352'>9353</a>\u001b[0m         right,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9353'>9354</a>\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9354'>9355</a>\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9355'>9356</a>\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9356'>9357</a>\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9357'>9358</a>\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9358'>9359</a>\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9359'>9360</a>\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9360'>9361</a>\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9361'>9362</a>\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9362'>9363</a>\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9363'>9364</a>\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/frame.py?line=9364'>9365</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:122\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=89'>90</a>\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=90'>91</a>\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=91'>92</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=104'>105</a>\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=105'>106</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=106'>107</a>\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=107'>108</a>\u001b[0m         left,\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=108'>109</a>\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=119'>120</a>\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=120'>121</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=121'>122</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:716\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=712'>713</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=713'>714</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=715'>716</a>\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_info()\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=717'>718</a>\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=718'>719</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39m_info_axis, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright\u001b[39m.\u001b[39m_info_axis, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuffixes\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=719'>720</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=721'>722</a>\u001b[0m lindexers \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: left_indexer} \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:967\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=962'>963</a>\u001b[0m     join_index, right_indexer, left_indexer \u001b[39m=\u001b[39m _left_join_on_index(\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=963'>964</a>\u001b[0m         right_ax, left_ax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys, sort\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=964'>965</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=965'>966</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=966'>967</a>\u001b[0m     (left_indexer, right_indexer) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_indexers()\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=968'>969</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=969'>970</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:941\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=938'>939</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_join_indexers\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]]:\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=939'>940</a>\u001b[0m     \u001b[39m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=940'>941</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m get_join_indexers(\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=941'>942</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, how\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow\n\u001b[1;32m    <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=942'>943</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1498\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1491'>1492</a>\u001b[0m lkey, rkey \u001b[39m=\u001b[39m _get_join_keys(llab, rlab, shape, sort)\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1493'>1494</a>\u001b[0m \u001b[39m# factorize keys to a dense i8 space\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1494'>1495</a>\u001b[0m \u001b[39m# `count` is the num. of unique keys\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1495'>1496</a>\u001b[0m \u001b[39m# set(lkey) | set(rkey) == range(count)\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1497'>1498</a>\u001b[0m lkey, rkey, count \u001b[39m=\u001b[39m _factorize_keys(lkey, rkey, sort\u001b[39m=\u001b[39;49msort, how\u001b[39m=\u001b[39;49mhow)\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1498'>1499</a>\u001b[0m \u001b[39m# preserve left frame order if how == 'left' and sort == False\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=1499'>1500</a>\u001b[0m kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(kwargs)\n",
      "File \u001b[0;32m~/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py:2191\u001b[0m, in \u001b[0;36m_factorize_keys\u001b[0;34m(lk, rk, sort, how)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2186'>2187</a>\u001b[0m llab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39mfactorize(lk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2187'>2188</a>\u001b[0m \u001b[39m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2188'>2189</a>\u001b[0m \u001b[39m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2189'>2190</a>\u001b[0m \u001b[39m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2190'>2191</a>\u001b[0m rlab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39;49mfactorize(rk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2191'>2192</a>\u001b[0m \u001b[39massert\u001b[39;00m llab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), llab\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   <a href='file:///home/alabai/studies/grammar_ru/grammar_ru/.venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py?line=2192'>2193</a>\u001b[0m \u001b[39massert\u001b[39;00m rlab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), rlab\u001b[39m.\u001b[39mdtype\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = run_training.run_local(bundle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CorpusReader(Loc.bundles_path/'chtoby/prepare/raw/raw.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = reader.get_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frames.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>reference_sentence_id</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Товарищеская</td>\n",
       "      <td>ru</td>\n",
       "      <td>12</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>встреча</td>\n",
       "      <td>ru</td>\n",
       "      <td>7</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1243</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>прошла</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1244</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1245</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>присутствии</td>\n",
       "      <td>ru</td>\n",
       "      <td>11</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1246</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50100</th>\n",
       "      <td>50100</td>\n",
       "      <td>47736</td>\n",
       "      <td>21</td>\n",
       "      <td>47728</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1439196</td>\n",
       "      <td>1317013</td>\n",
       "      <td>1311705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50101</th>\n",
       "      <td>50101</td>\n",
       "      <td>47736</td>\n",
       "      <td>22</td>\n",
       "      <td>47728</td>\n",
       "      <td>1</td>\n",
       "      <td>чтобы</td>\n",
       "      <td>ru</td>\n",
       "      <td>5</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1439197</td>\n",
       "      <td>1317013</td>\n",
       "      <td>1311705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50102</th>\n",
       "      <td>50102</td>\n",
       "      <td>47736</td>\n",
       "      <td>23</td>\n",
       "      <td>47728</td>\n",
       "      <td>1</td>\n",
       "      <td>потрясти</td>\n",
       "      <td>ru</td>\n",
       "      <td>8</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1439198</td>\n",
       "      <td>1317013</td>\n",
       "      <td>1311705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50103</th>\n",
       "      <td>50103</td>\n",
       "      <td>47736</td>\n",
       "      <td>24</td>\n",
       "      <td>47728</td>\n",
       "      <td>0</td>\n",
       "      <td>нигерийца</td>\n",
       "      <td>ru</td>\n",
       "      <td>9</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1439199</td>\n",
       "      <td>1317013</td>\n",
       "      <td>1311705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50104</th>\n",
       "      <td>50104</td>\n",
       "      <td>47736</td>\n",
       "      <td>25</td>\n",
       "      <td>47728</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1439200</td>\n",
       "      <td>1317013</td>\n",
       "      <td>1311705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49985 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_id  sentence_id  word_index  paragraph_id  word_tail  \\\n",
       "0            0            0           0             0          1   \n",
       "1            1            0           1             0          1   \n",
       "2            2            0           2             0          1   \n",
       "3            3            0           3             0          1   \n",
       "4            4            0           4             0          1   \n",
       "...        ...          ...         ...           ...        ...   \n",
       "50100    50100        47736          21         47728          1   \n",
       "50101    50101        47736          22         47728          1   \n",
       "50102    50102        47736          23         47728          1   \n",
       "50103    50103        47736          24         47728          0   \n",
       "50104    50104        47736          25         47728          1   \n",
       "\n",
       "               word word_type  word_length  \\\n",
       "0      Товарищеская        ru           12   \n",
       "1           встреча        ru            7   \n",
       "2            прошла        ru            6   \n",
       "3                 в        ru            1   \n",
       "4       присутствии        ru           11   \n",
       "...             ...       ...          ...   \n",
       "50100             ,     punct            1   \n",
       "50101         чтобы        ru            5   \n",
       "50102      потрясти        ru            8   \n",
       "50103     нигерийца        ru            9   \n",
       "50104             .     punct            1   \n",
       "\n",
       "                                    file_id corpus_id original_corpus_id  \\\n",
       "0      2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "1      2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "2      2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "3      2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "4      2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "...                                     ...       ...                ...   \n",
       "50100  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "50101  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "50102  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "50103  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "50104  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip     lenta.base.zip   \n",
       "\n",
       "       is_target  label  reference_sentence_id  original_word_id  \\\n",
       "0          False      0                    0.0              1242   \n",
       "1          False      0                    0.0              1243   \n",
       "2          False      0                    0.0              1244   \n",
       "3          False      0                    0.0              1245   \n",
       "4          False      0                    0.0              1246   \n",
       "...          ...    ...                    ...               ...   \n",
       "50100      False      0                  997.0           1439196   \n",
       "50101       True      0                  997.0           1439197   \n",
       "50102      False      0                  997.0           1439198   \n",
       "50103      False      0                  997.0           1439199   \n",
       "50104      False      0                  997.0           1439200   \n",
       "\n",
       "       original_sentence_id  original_paragraph_id  updated  \n",
       "0                        65                      9    False  \n",
       "1                        65                      9    False  \n",
       "2                        65                      9    False  \n",
       "3                        65                      9    False  \n",
       "4                        65                      9    False  \n",
       "...                     ...                    ...      ...  \n",
       "50100               1317013                1311705    False  \n",
       "50101               1317013                1311705    False  \n",
       "50102               1317013                1311705    False  \n",
       "50103               1317013                1311705    False  \n",
       "50104               1317013                1311705    False  \n",
       "\n",
       "[49985 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>reference_sentence_id</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4993</td>\n",
       "      <td>4993</td>\n",
       "      <td>0</td>\n",
       "      <td>4993</td>\n",
       "      <td>1</td>\n",
       "      <td>Товарищеская</td>\n",
       "      <td>ru</td>\n",
       "      <td>12</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4994</td>\n",
       "      <td>4993</td>\n",
       "      <td>1</td>\n",
       "      <td>4993</td>\n",
       "      <td>1</td>\n",
       "      <td>встреча</td>\n",
       "      <td>ru</td>\n",
       "      <td>7</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>4993</td>\n",
       "      <td>2</td>\n",
       "      <td>4993</td>\n",
       "      <td>1</td>\n",
       "      <td>прошла</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>4993</td>\n",
       "      <td>3</td>\n",
       "      <td>4993</td>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>4993</td>\n",
       "      <td>4</td>\n",
       "      <td>4993</td>\n",
       "      <td>1</td>\n",
       "      <td>присутствии</td>\n",
       "      <td>ru</td>\n",
       "      <td>11</td>\n",
       "      <td>2917e260-0518-49a5-8b7b-75b7af3f7891</td>\n",
       "      <td>raw.zip</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_id  sentence_id  word_index  paragraph_id  word_tail          word  \\\n",
       "4993     4993         4993           0          4993          1  Товарищеская   \n",
       "4994     4994         4993           1          4993          1       встреча   \n",
       "4995     4995         4993           2          4993          1        прошла   \n",
       "4996     4996         4993           3          4993          1             в   \n",
       "4997     4997         4993           4          4993          1   присутствии   \n",
       "\n",
       "     word_type  word_length                               file_id corpus_id  \\\n",
       "4993        ru           12  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip   \n",
       "4994        ru            7  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip   \n",
       "4995        ru            6  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip   \n",
       "4996        ru            1  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip   \n",
       "4997        ru           11  2917e260-0518-49a5-8b7b-75b7af3f7891   raw.zip   \n",
       "\n",
       "     original_corpus_id  is_target  label  reference_sentence_id  \\\n",
       "4993               None      False      1                    NaN   \n",
       "4994               None      False      1                    NaN   \n",
       "4995               None      False      1                    NaN   \n",
       "4996               None      False      1                    NaN   \n",
       "4997               None      False      1                    NaN   \n",
       "\n",
       "      original_word_id  original_sentence_id  original_paragraph_id  updated  \n",
       "4993                 0                     0                      0    False  \n",
       "4994                 1                     0                      0    False  \n",
       "4995                 2                     0                      0    False  \n",
       "4996                 3                     0                      0    False  \n",
       "4997                 4                     0                      0    False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame['label'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06d5edd100e8af3ad61bcb86118b225055d5ada911b896704585f9e786ce8d1b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
