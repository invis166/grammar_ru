{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.ml.corpus import CorpusReader\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = 'lenta.base.zip'\n",
    "reader = CorpusReader(Loc.corpus_path/corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = reader.read_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frames.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Американские</td>\n",
       "      <td>ru</td>\n",
       "      <td>12</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>войска</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>продвигаются</td>\n",
       "      <td>ru</td>\n",
       "      <td>12</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>к</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>центру</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>города</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Неджеф</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>сообщает</td>\n",
       "      <td>ru</td>\n",
       "      <td>8</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>агентство</td>\n",
       "      <td>ru</td>\n",
       "      <td>9</td>\n",
       "      <td>bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8</td>\n",
       "      <td>lenta.base.zip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  word_index  paragraph_id  word_tail          word  \\\n",
       "0        0            0           0             0          1  Американские   \n",
       "1        1            0           1             0          1        войска   \n",
       "2        2            0           2             0          1  продвигаются   \n",
       "3        3            0           3             0          1             к   \n",
       "4        4            0           4             0          1        центру   \n",
       "5        5            0           5             0          1        города   \n",
       "6        6            0           6             0          0        Неджеф   \n",
       "7        7            0           7             0          1             ,   \n",
       "8        8            0           8             0          1      сообщает   \n",
       "9        9            0           9             0          1     агентство   \n",
       "\n",
       "  word_type  word_length                               file_id       corpus_id  \n",
       "0        ru           12  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "1        ru            6  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "2        ru           12  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "3        ru            1  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "4        ru            6  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "5        ru            6  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "6        ru            6  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "7     punct            1  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "8        ru            8  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  \n",
       "9        ru            9  bbd53cdb-f9c2-4ee9-8a0e-0238e52253d8  lenta.base.zip  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_single_n(df):\n",
    "    single_n_regex = '[^н]н[^н](?!.*?нн)'  # matches only 'н' not followed by 'нн'\n",
    "    df_with_single = frame[frame['word'].str.contains(single_n_regex)]  \n",
    "\n",
    "    return df_with_single\n",
    "\n",
    "def get_df_with_double_n(df):\n",
    "    double_n_regex = r'нн(?!.+?н)'  # matches only 'нн' not followed by 'н'\n",
    "    df_with_double = frame[frame['word'].str.contains(double_n_regex)]\n",
    "\n",
    "    return df_with_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_double_n_to_single_and_lemmatize(nlp, df):\n",
    "    df_with_double_replaced_to_single = df_with_double['word'].str[::-1].str.replace('нн', 'н', 1).str[::-1]\n",
    "    words_with_double_replaced_to_single = {token.lemma_ for token in nlp('. '.join(df_with_double_replaced_to_single))}\n",
    "\n",
    "    return words_with_double_replaced_to_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_with_lemmatization(nlp, df):\n",
    "    df_with_single = get_df_with_single_n(df)\n",
    "    df_with_double = get_df_with_double_n(df)\n",
    "\n",
    "    words_with_double_replaced_to_single = replace_double_n_to_single_and_lemmatize(nlp, df_with_double)\n",
    "    words_with_single = {token.lemma_ for token in nlp('. '.join(df_with_single['word']))}\n",
    "\n",
    "    union = words_with_single.intersection(words_with_double_replaced_to_single)\n",
    "\n",
    "    return union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from tg.grammar_ru.ml.tasks.n_nn import bundle\n",
    "build_dictionary = reload(bundle).build_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.tasks.n_nn.bundle import build_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = build_dictionary([frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Американские\n",
       "4               центру\n",
       "9            агентство\n",
       "14        командование\n",
       "18         Специальные\n",
       "              ...     \n",
       "184984      подписание\n",
       "184985      соглашения\n",
       "184987     возвращению\n",
       "184989       мигрантов\n",
       "184992      транзитный\n",
       "Name: word, Length: 35888, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[frame.word.str.contains(r'[^н]н[^н](?!.*?нн)')].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced = np.where(\n",
    "    frame.word.str.contains(r'[^н]н[^н](?!.*?нн)'),\n",
    "    frame.word.str[::-1].str.replace('н', 'нн', 1).str[::-1],\n",
    "    frame.word.str[::-1].str.replace('нн', 'н', 1).str[::-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from tg.grammar_ru.ml.tasks.train_index_builder import index_builders\n",
    "NNnIndexBuilder = reload(index_builders).NNnIndexBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.tasks.train_index_builder.index_builders import TsaIndexBuilder, NNnIndexBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yo_fluq_ds import FileIO\n",
    "words = FileIO.read_json('/home/alabai/studies/grammar_ru/grammar_ru/research/n_nn/words.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nn_index_builder = NNnIndexBuilder(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_target'] = n_nn_index_builder._get_targets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = n_nn_index_builder._build_positive(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20          подразделения\n",
       "23                окраины\n",
       "26        военизированных\n",
       "39            применением\n",
       "47                    дом\n",
       "               ...       \n",
       "184939         президента\n",
       "184968           заключил\n",
       "184984         подписание\n",
       "184987        возвращению\n",
       "184988         незаконных\n",
       "Name: word, Length: 16789, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive[positive.is_target].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = positive.copy()\n",
    "negative.word = np.where(\n",
    "    ~negative.is_target,\n",
    "    negative.word,\n",
    "    np.where(\n",
    "        negative.word.str.contains(r'[^н]н[^н](?!.*?нн)'),\n",
    "        negative.word.str[::-1].str.replace('н', 'нн', 1).str[::-1],\n",
    "        negative.word.str[::-1].str.replace('нн', 'н', 1).str[::-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20        подразделенния\n",
       "23              окраинны\n",
       "26        военизированых\n",
       "39          примененнием\n",
       "47                   дом\n",
       "               ...      \n",
       "184939       президеннта\n",
       "184968          заключил\n",
       "184984       подписанние\n",
       "184987      возвращеннию\n",
       "184988         незаконых\n",
       "Name: word, Length: 16789, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[negative.is_target].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06d5edd100e8af3ad61bcb86118b225055d5ada911b896704585f9e786ce8d1b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
